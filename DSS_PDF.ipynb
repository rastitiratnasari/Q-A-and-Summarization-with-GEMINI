{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient Information Extraction: Q&A and Summarization over PDF Documents using LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading PDF file\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_load = PyPDFLoader('Jurnal_Machine learning.pdf', extract_images=True)\n",
    "pdf_file = pdf_load.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data type\n",
    "type(pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check elements  in data list\n",
    "len(pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M. Bansal, A. Goyal and A. Choudhary Decision Analytics Journal 3 (2022) 100071\n",
      "Fig. 1. Classification of Machine Learning Algorithms [2].\n",
      "exact outputs with some random data. The theory of supervised type\n",
      "of learning is centered on the word ‘supervision’, where it aims at\n",
      "mapping the data associated with the input to that associated with\n",
      "the output. This method undoubtedly needs a substantial amount of\n",
      "human application to construct the model, but eventually leads to faster\n",
      "performance of an otherwise tedious task. Supervised machine learning\n",
      "is a widely adopted category of Machine learning. This is further\n",
      "classified into Regression algorithms and Classification algorithms [1].\n",
      "1.1.2. Unsupervised learning\n",
      "Unsupervised learning enables the machine to learn without any\n",
      "supervision. In unsupervised learning, an unsegregated and unlabeled\n",
      "data set is provided to the machine, and the algorithm is supposed\n",
      "to perform on the data without any supervision. This theory aims\n",
      "at regrouping the input data elements exhibiting like patterns. It is\n",
      "not possible to predict any outcomes in this theory, and the machine\n",
      "attempts to present important understandings based on the enormous\n",
      "amount of data. This is again further divided into Clustering and\n",
      "Association [1].\n",
      "1.1.3. Reinforcement learning\n",
      "This theory exists as a feedback-based mechanism, where the learner\n",
      "is rewarded for each correct move, and penalized for the incorrect\n",
      "action. With these prompts, the learners, can mend the system and\n",
      "increase its performance. In this type of learning, the person basically\n",
      "intermingles with the environment and tries to discover more about\n",
      "it [1]. As mentioned earlier, there are two categories under supervised\n",
      "learning, regression, and classification. The algorithms belonging to the\n",
      "regression sub-category are useful when the input variable is related to\n",
      "the output variable in some way, and it is required to predict variables\n",
      "of continuous nature, like stocks, or some population trends. Whereas,\n",
      "classification algorithms are handy when the outcome is of categorical\n",
      "nature, like ‘Circle or Triangle, true or False, Right or left, Yes or No’,\n",
      "etc.\n",
      "2. K-nearest neighbor algorithm (K-NN)\n",
      "K-nearest-neighbor (K-NN) being one of the most essential and\n",
      "effective algorithms for data segregation is capable of becoming the\n",
      "primary choice for implementation especially when the given datais quite ambiguous. This algorithm was invented back in 1951 by\n",
      "Evelyn Fix and Joseph Hodges for discriminant examination when\n",
      "it was relatively challenging to decide the probabilistic densities by\n",
      "parametric estimation [3]. Further in the year 1967, a couple of charac-\n",
      "teristics belonging to this algorithm were calculated, for example where\n",
      "‘k’=1 and ‘n’ tends to infinity then the K-NN classification fallacy\n",
      "or error is limited above by two times the error rate of Bayes [4].\n",
      "Post establishment of such particular characteristics and properties,\n",
      "research and experimentation followed over long periods to count\n",
      "novel rejection approaches [5], improvements for Bayes error rate [6],\n",
      "procedures relying solely on distance [7], [8], methods for soft comput-\n",
      "ing [9] and other approaches. The K-NN algorithm is positioned under\n",
      "the supervised type learning technique and is considered one of the\n",
      "easiest-to-use algorithms in Machine Learning. Although it is suited for\n",
      "classifying as well as regressing both, it is predominantly utilized for\n",
      "classifying objects. It is an extremely handy algorithm, used to assign\n",
      "any missing value and to re-sample the data [10]. For a given data set,\n",
      "this algorithm predicts the connection among the unseen data and the\n",
      "already existing data and based on that prediction, it imputes the new\n",
      "data to a prevailing category that best matches with it. Therefore, fresh\n",
      "data can be certainly classified by the K-NN algorithm. It sorts the new\n",
      "data point or figure based on arrangements of its neighbors. K-NN can\n",
      "also be referred to as the lazy learner algorithm, as the data set is only\n",
      "stored initially, but the learning process of the training data set does\n",
      "not take place until there is a demand for classification or prediction of\n",
      "the new data set. It is also non-parametric in nature, i.e., in K-NN there\n",
      "does not exist any predetermined method or form of the relationship\n",
      "between the input and output [11].\n",
      "In Fig. 2, there are two cases, either benign tumor, or malignant\n",
      "tumor. A separate data point has been assigned to be specified as either\n",
      "benign or malignant. In this case, K-NN algorithm can easily help the\n",
      "analyzers in the classification procedure of the new different point from\n",
      "the data set on the basis of the likeness or similarity index of the point\n",
      "with both the existing cases. K-NN can be used when, the data set taken\n",
      "is labeled, and noise free.\n",
      "2.1. Working of KNN algorithm\n",
      "The ‘K’ here in K-NN refers to the count of neighbors of the new\n",
      "data point. Deciding a suitable value for K is the foremost process in\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Check content in data list\n",
    "print(pdf_file[2].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process to create smaller chunks from previously extracted content. Smaller chunks are easier to maintain, store, and process by the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this splitting process, we're utilizing RecursiveCharacterTextSplitter(). Splitting technique with RecursiveCharacterTextSplitter() is recommended for initiating splitting from a considerably large text.\n",
    "\n",
    "Next, we input the pdf_data list into the .split_documents() method. This method will create smaller chunks from pdf_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To split the content of a PDF file into smaller chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500, # max character\n",
    "    chunk_overlap = 250, # The maximum number of characters that are the same\n",
    "    separators=[\n",
    "                \"\\n\\n\",\n",
    "                \"\\n\",\n",
    "                \" \",\n",
    "                \".\",\n",
    "                \",\",\n",
    "                \"\\u200b\",  # zero-width space\n",
    "                \"\\uff0c\",  # full-width comma\n",
    "                \"\\u3001\",  # ideographic comma\n",
    "                \"\\uff0e\",  # full-width full stop\n",
    "                \"\\u3002\",  # ideographic full stop\n",
    "                \"\",\n",
    "            ])\n",
    "\n",
    "splits = text_splitter.split_documents(pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check elements  in data list after split process\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got 414 chunks as a result of splitting 21 elements from the pdf_file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding and Storing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Embedding process is a procedure to create numerical representations of text so that the text can be understood by computers. LangChain provides embedding options, and the one we will use is GoogleGenerativeEmbeddings() for the LLM model developed by Google.\n",
    "\n",
    "The content of the PDF file, which is already in numerical form, will then be stored in the vector database.\n",
    "The vector database we will use is Chroma. Chroma is a vector database capable of storing unstructured data, such as the content of PDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rastiti Ratnasari\\miniconda3\\envs\\dss_may2024\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# embedding\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings # embedding Google Generative AI\n",
    "\n",
    "# save embedding to database\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dvectorstore_gemini = create_vectorstore_folder(\n",
    "     #documents = splits,\n",
    "     #embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"),\n",
    "    #persist_directory = 'data_input/chroma_gemini'\n",
    " #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call embedding from directory in database\n",
    "vec_gemini = Chroma(persist_directory= 'data_input/chroma_gemini',\n",
    "                    embedding_function= GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a chain that allows us to query the LLM involves the following steps: The LLM will provide answers based on the information stored in a vector database. When we present a question (query) to the LLM, it will be converted into a numerical representation (vector). This numerical representation will then be used to search for relevant answers based on the information in the vector database. This process involves calculating vector similarity between the query vector and the vectors representing information in the vector database. Information with a high level of similarity will be returned as the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# prepare prompt\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# Question input\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "# sow output\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_template = \"\"\"\n",
    "    You are the great assistant in understanding additional context\n",
    "\n",
    "    Use the following pieces of context to answer the question at the end.\n",
    "    Use the minimum of three sentences to answer the question. \n",
    "    Try your best to answer as complete as possible with easy style of English.\n",
    "    Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Helpful Answer:\"\"\"\n",
    "\n",
    "custom_rag_prompt = PromptTemplate.from_template(qa_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa_chain(retriever, llm):\n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} \n",
    "        | custom_rag_prompt # prompt for direct to output & LLM.\n",
    "        | llm               \n",
    "        | StrOutputParser() # will capture the output from the LLM\n",
    "    )\n",
    "\n",
    "    return rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_chain = create_qa_chain(retriever= vec_gemini.as_retriever(),\n",
    "                               llm= ChatGoogleGenerativeAI(model= \"gemini-pro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper discusses various machine learning algorithms including Decision Tree (DT),\n",
      "Support Vector Machine (SVM), and many others. The DT algorithm is used for classification\n",
      "and regression tasks, while the SVM algorithm is used for classification tasks. The paper\n",
      "also highlights the future scope of ML algorithms and artificial intelligence in the\n",
      "coming times and their roles in automation and holistic development. Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    textwrap.fill(\n",
    "        gemini_chain.invoke('What machine learning algorithms are discussed in this paper?'),\n",
    "        width=90\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic algorithm is mainly a probability-based optimization algorithm. Similar to\n",
      "genetics from biology, here, the multiple solutions form a population. Each solution in\n",
      "the population has a set of properties which can be mutated and altered. Genetic\n",
      "algorithms have both advantages and drawbacks.  Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    textwrap.fill(\n",
    "        gemini_chain.invoke('What is Genetic algorithm?'),\n",
    "        width=90\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Chatbot-Like Interaction with `while` Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAsk The PDF!\u001b[0m\n",
      "\n",
      "\u001b[1mQuestion:\u001b[0m\n",
      "what is support vector machines?\n",
      "\u001b[1mResponse:\u001b[0m\n",
      "Support vector machines (SVMs) are a powerful machine learning algorithm used for\n",
      "classification and regression tasks. They construct a hyperplane or set of hyperplanes in\n",
      "a high-dimensional space to separate different classes of data points. The goal is to find\n",
      "the hyperplane that best separates the data while maximizing the margin, which is the\n",
      "distance between the hyperplane and the closest data points of different classes. SVMs are\n",
      "known for their ability to handle complex and non-linear data, making them a popular\n",
      "choice for a wide range of applications, including image classification, text\n",
      "classification, and bioinformatics. Thanks for asking!\n",
      "\n",
      "\u001b[1mQuestion:\u001b[0m\n",
      "exit\n",
      "Exiting\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rastiti Ratnasari\\miniconda3\\envs\\dss_may2024\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(\"\\033[1mAsk The PDF!\\033[0m\")\n",
    "print('')\n",
    "while True:\n",
    "    \n",
    "    print('\\033[1mQuestion:\\033[0m')\n",
    "\n",
    "    query = input('')\n",
    "    print(query)\n",
    "\n",
    "    #To exit: use 'exit', 'quit', 'q', or Ctrl-D.\",\n",
    "    if query.lower() in [\"exit\", \"quit\", \"q\"]:\n",
    "        print('Exiting')\n",
    "        sys.exit()\n",
    "\n",
    "    print('\\033[1mResponse:\\033[0m')\n",
    "    response = textwrap.fill(gemini_chain.invoke(query), width=90)\n",
    "    print(response)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides being to create Q&A systems, LLM is also frequently utilized for task summarization. We will define a chain with LCEL to perform summarization on the \"Journal_Machine learning\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file\n",
    "pdf_load= PyPDFLoader('Jurnal_Machine learning.pdf')\n",
    "Jurnal_content = pdf_load.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indentify promt to make summary\n",
    "summary_template = \"\"\"\n",
    "    You are the great assistant in summarizing the following passage.\n",
    "\n",
    "    Provide a summary of the following passage. \n",
    "    The summary should be general and no longer than five sentences.\n",
    "\n",
    "    Passage:\n",
    "    ```{text}```\n",
    "    \n",
    "    Summary:\n",
    "\"\"\"\n",
    "\n",
    "custom_summary_prompt = PromptTemplate.from_template(summary_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify a fuction that will return the chain for summarizer\n",
    "def create_summary_chain(llm):\n",
    "    summary_chain = {'text':RunnablePassthrough()} | custom_summary_prompt | llm | StrOutputParser()\n",
    "    return summary_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create chain\n",
    "gemini_summarizer = create_summary_chain(llm= ChatGoogleGenerativeAI(model='gemini-pro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Machine learning algorithms are a new-age thriving technology,\n",
      "which facilitates computers to read and interpret data automatically.\n",
      "2. Five machine learning algorithms namely- K-Nearest Neighbor (K-NN),\n",
      "Genetic Algorithm (GA), Support Vector Machine (SVM), Decision Tree\n",
      "(DT), and Long Short-Term Memory (LSTM) algorithms in machine learning\n",
      "are discussed in detail.  3. K-NN algorithm is an easy-to-use\n",
      "algorithm that is tolerant and resistant to noise prevailing in the\n",
      "data set used for training.  4. GA is a subset of a relatively much\n",
      "larger domain of computation known as Evolutionary Computation.  5.\n",
      "SVM algorithm is intended for regression and classification problems.\n",
      "6. DT algorithm is mostly preferred for solving classification\n",
      "problems but either way, it may be used in classifying as well as in\n",
      "regressing cases.  7. LSTM algorithm is a special case recurrent\n",
      "neural network (RNN) that is well equipped to handle long-term\n",
      "dependencies by default.  8. LSTM network and the SVM algorithm have\n",
      "rendered one of the best results when it comes to predictive analytics\n",
      "in real-time applications related to multidisciplinary spheres like\n",
      "medicine, bank frauds, face detection, student performance prediction,\n",
      "electricity usage prediction, etc. 9. The future scope highlights, the\n",
      "expected demand and popularity of machine learning and artificial\n",
      "intelligence in the future, which is anticipated to either support\n",
      "humans in multiple fields or completely replace them and bring in\n",
      "automation at a large scale and pace with the help of more advanced\n",
      "and rigorous research.\n"
     ]
    }
   ],
   "source": [
    "# running chain\n",
    "print(\n",
    "    textwrap.fill(\n",
    "        gemini_summarizer.invoke(Jurnal_content)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return Source of QnA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a chain where, besides providing an answer, it will also offer the resources used to derive that answer. Thus, it is expected to verify the accuracy of the LLM's response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa_chain_with_source(retriever, llm):\n",
    "\n",
    "    rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    ).assign(answer=rag_chain_from_docs)\n",
    "\n",
    "    return rag_chain_with_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_gemini_source = create_qa_chain_with_source(retriever = vec_gemini.as_retriever(),\n",
    "                                               llm = ChatGoogleGenerativeAI(model = 'gemini-pro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='6. Long Short-Term Memory (LSTM) algorithm ........................................................................................................................................................ 14\\n6.1. Structure of LSTM .................................................................................................................................................................................. 14', metadata={'page': 1, 'source': 'Jurnal_Machine learning.pdf'}),\n",
       "  Document(page_content='6.4. Advantages of LSTM algorithm................................................................................................................................................................ 16\\n6.5. Drawbacks of LSTM algorithm................................................................................................................................................................. 16', metadata={'page': 1, 'source': 'Jurnal_Machine learning.pdf'}),\n",
       "  Document(page_content='5.7. Drawbacks of decision tree algorithm....................................................................................................................................................... 14\\n6. Long Short-Term Memory (LSTM) algorithm ........................................................................................................................................................ 14', metadata={'page': 1, 'source': 'Jurnal_Machine learning.pdf'}),\n",
       "  Document(page_content='the error-incorporated signals running rearward in time are likely to\\ndisappear or blow up; the temporal shifts of the error incorporated\\nsignal to a great extent relies on the weight sizes. In case of blowing\\nup, the weights are quite likely to start oscillating and in case of\\ndisappearance, either the time consumed to learn bridging longer time\\nlags is out of bounds, or in the worst case it does not work [45]. As a\\nremedy, the Long Short-Term Memory (LSTM) algorithm, a novel type', metadata={'page': 13, 'source': 'Jurnal_Machine learning.pdf'})],\n",
       " 'question': 'What is  Long Short-Term Memory (LSTM) algorithm?',\n",
       " 'answer': 'Long Short-Term Memory (LSTM) algorithm is a novel type of recurrent neural network (RNN) that was developed to address the vanishing gradient problem. \\nUnlike traditional RNNs, LSTMs have a special internal structure called a memory cell, which allows them to learn long-term dependencies in data. \\nThis makes them particularly well-suited for tasks such as natural language processing and time series analysis.\\nThanks for asking!'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_gemini_source.invoke('What is  Long Short-Term Memory (LSTM) algorithm?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Summarization using ROUGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics that we can use to evaluate the output of LLM is ROUGE (Recall-Oriented Understudy for Gisting Evaluation). ROUGE works by comparing the similarity of two texts. In this case, the text generated by GEMINI and the reference text serve as our standards for assessing the quality of LLM output.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six in c:\\users\\rastiti ratnasari\\miniconda3\\envs\\dss_may2024\\lib\\site-packages (from rouge) (1.16.0)\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n"
     ]
    }
   ],
   "source": [
    "# install package ROUGE\n",
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_text = '''\n",
    "Transformers have achieved superior performances\n",
    "in many tasks in natural language processing and\n",
    "computer vision, which also triggered great interest in the time series community. \n",
    "Among multiple advantages of Transformers, the ability to capture\n",
    "long-range dependencies and interactions is especially attractive for time series modeling, leading\n",
    "to exciting progress in various time series applications. \n",
    "In this paper, we systematically review Transformer schemes for time series modeling by\n",
    "highlighting their strengths as well as limitations.\n",
    "In particular, we examine the development of time\n",
    "series Transformers in two perspectives. From the\n",
    "perspective of network structure, we summarize the\n",
    "adaptations and modifcations that have been made\n",
    "to Transformers in order to accommodate the challenges in time series analysis. From the perspective\n",
    "of applications, we categorize time series Transformers based on common tasks including forecasting, anomaly detection, and classifcation. Empirically, we perform robust analysis, model size analysis, and seasonal-trend decomposition analysis to\n",
    "study how Transformers perform in time series. Finally, we discuss and suggest future directions to\n",
    "provide useful research guidance.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_generated_summary = '''\n",
    "Transformers have shown significant advancements in various domains,\n",
    "including natural language processing and computer vision. They are\n",
    "now being applied to time series modeling due to their ability to\n",
    "capture long-range dependencies. Various adaptations and modifications\n",
    "have been made to Transformers to address challenges in time series\n",
    "analysis. These modifications include positional encodings, attention\n",
    "modules, and architecture-level innovations. Transformers have been\n",
    "successfully applied to tasks such as forecasting, anomaly detection,\n",
    "and classification in time series data. Future research opportunities\n",
    "include exploring inductive biases, combining Transformers with graph\n",
    "neural networks, developing pre-trained models for time series,\n",
    "designing architecture-level variants, and utilizing neural\n",
    "architecture search for optimal Transformer design.Machine learning algorithms are a new-age thriving technology,\n",
    "which facilitates computers to read and interpret data automatically.\n",
    "2. Five machine learning algorithms namely- K-Nearest Neighbor (K-NN),\n",
    "Genetic Algorithm (GA), Support Vector Machine (SVM), Decision Tree\n",
    "(DT), and Long Short-Term Memory (LSTM) algorithms in machine learning\n",
    "are discussed in detail.  3. K-NN algorithm is an easy-to-use\n",
    "algorithm that is tolerant and resistant to noise prevailing in the\n",
    "data set used for training.  4. GA is a subset of a relatively much\n",
    "larger domain of computation known as Evolutionary Computation.  5.\n",
    "SVM algorithm is intended for regression and classification problems.\n",
    "6. DT algorithm is mostly preferred for solving classification\n",
    "problems but either way, it may be used in classifying as well as in\n",
    "regressing cases.  7. LSTM algorithm is a special case recurrent\n",
    "neural network (RNN) that is well equipped to handle long-term\n",
    "dependencies by default.  8. LSTM network and the SVM algorithm have\n",
    "rendered one of the best results when it comes to predictive analytics\n",
    "in real-time applications related to multidisciplinary spheres like\n",
    "medicine, bank frauds, face detection, student performance prediction,\n",
    "electricity usage prediction, etc. 9. The future scope highlights, the\n",
    "expected demand and popularity of machine learning and artificial\n",
    "intelligence in the future, which is anticipated to either support\n",
    "humans in multiple fields or completely replace them and bring in\n",
    "automation at a large scale and pace with the help of more advanced\n",
    "and rigorous research.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'r': 0.4036697247706422,\n",
       "   'p': 0.19213973799126638,\n",
       "   'f': 0.2603550252160289},\n",
       "  'rouge-2': {'r': 0.17647058823529413,\n",
       "   'p': 0.08307692307692308,\n",
       "   'f': 0.11297070694446892},\n",
       "  'rouge-l': {'r': 0.3761467889908257,\n",
       "   'p': 0.17903930131004367,\n",
       "   'f': 0.24260354592608807}}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation output with ROUGE\n",
    "evaluator = Rouge()\n",
    "evaluator.get_scores(llm_generated_summary, abstract_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dss_may2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
